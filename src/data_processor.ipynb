{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel 'venv (Python 3.9.2)'. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. listen EFAULT: bad address in system call argument :::9000"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "\"\"\"\n",
        "금융 데이터 처리 모듈\n",
        "- 수집된 데이터 전처리\n",
        "- 벡터 DB 구축\n",
        "- 데이터 분석 및 특성 추출\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import joblib\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "from .db_client import get_supabase_client\n",
        "\n",
        "class DataProcessor:\n",
        "    \"\"\"금융 데이터 처리 클래스\"\"\"\n",
        "    def __init__(self):\n",
        "        self.script_dir = os.path.dirname(os.path.abspath(__file__))\n",
        "        self.data_dir = os.path.join(os.path.dirname(self.script_dir), \"data\")\n",
        "        self.raw_data_dir = os.path.join(self.data_dir, \"raw\")\n",
        "        self.processed_data_dir = os.path.join(self.data_dir, \"processed\")\n",
        "        \n",
        "        # 디렉토리 초기화\n",
        "        os.makedirs(self.raw_data_dir, exist_ok=True)\n",
        "        os.makedirs(self.processed_data_dir, exist_ok=True)\n",
        "        \n",
        "        # 임베딩 모델 로드\n",
        "        self.embedding_model = self._load_embedding_model()\n",
        "        \n",
        "        # 벡터 DB 관련 변수\n",
        "        self.vector_db_index = None\n",
        "        self.document_store = []\n",
        "    \n",
        "    def _load_embedding_model(self):\n",
        "        \"\"\"문장 임베딩 모델 로드\"\"\"\n",
        "        try:\n",
        "            # 한국어에 최적화된 모델\n",
        "            return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "        except Exception as e:\n",
        "            print(f\"임베딩 모델 로드 실패: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def process_stock_tickers(self):\n",
        "        \"\"\"종목 코드 데이터 처리\"\"\"\n",
        "        try:\n",
        "            print(\"종목 코드 데이터 처리 중...\")\n",
        "            \n",
        "            # 최신 종목 코드 파일 찾기\n",
        "            ticker_files = sorted([f for f in os.listdir(self.raw_data_dir) if f.startswith('kor_ticker_')], reverse=True)\n",
        "            if not ticker_files:\n",
        "                print(\"종목 코드 파일이 없습니다.\")\n",
        "                return None\n",
        "            \n",
        "            ticker_file = os.path.join(self.raw_data_dir, ticker_files[0])\n",
        "            ticker_df = pd.read_csv(ticker_file)\n",
        "            \n",
        "            # 데이터 전처리\n",
        "            # 종목코드 6자리로 포맷팅\n",
        "            ticker_df['종목코드'] = ticker_df['종목코드'].astype(str).str.zfill(6)\n",
        "            \n",
        "            # 결측치 처리\n",
        "            if '섹터' in ticker_df.columns:\n",
        "                ticker_df['섹터'] = ticker_df['섹터'].fillna('기타')\n",
        "            \n",
        "            # 처리된 데이터 저장\n",
        "            output_file = os.path.join(self.processed_data_dir, \"stock_tickers.pkl\")\n",
        "            ticker_df.to_pickle(output_file)\n",
        "            \n",
        "            print(f\"종목 코드 데이터 처리 완료: {len(ticker_df)}개 종목, 저장 경로: {output_file}\")\n",
        "            return ticker_df\n",
        "        except Exception as e:\n",
        "            print(f\"종목 코드 데이터 처리 실패: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def process_stock_prices(self):\n",
        "        \"\"\"주식 가격 데이터 처리\"\"\"\n",
        "        try:\n",
        "            print(\"국내주식 가격 데이터 처리 중...\")\n",
        "            \n",
        "            # 최신 가격 데이터 파일 찾기\n",
        "            price_files = sorted([f for f in os.listdir(self.raw_data_dir) if f.startswith('kor_price_')], reverse=True)\n",
        "            if not price_files:\n",
        "                print(\"가격 데이터 파일이 없습니다.\")\n",
        "                return None\n",
        "            \n",
        "            price_file = os.path.join(self.raw_data_dir, price_files[0])\n",
        "            price_df = pd.read_csv(price_file)\n",
        "            \n",
        "            # 데이터 전처리\n",
        "            # 날짜 형식 변환\n",
        "            if '날짜' in price_df.columns:\n",
        "                price_df['날짜'] = pd.to_datetime(price_df['날짜'])\n",
        "            \n",
        "            # 결측치 처리\n",
        "            for col in ['시가', '고가', '저가', '종가', '거래량']:\n",
        "                if col in price_df.columns:\n",
        "                    price_df[col] = price_df[col].fillna(method='ffill')\n",
        "            \n",
        "            # 기술적 지표 추가\n",
        "            price_df = self._add_technical_indicators(price_df)\n",
        "            \n",
        "            # 처리된 데이터 저장\n",
        "            output_file = os.path.join(self.processed_data_dir, \"stock_prices.pkl\")\n",
        "            price_df.to_pickle(output_file)\n",
        "            \n",
        "            print(f\"국내주식 가격 데이터 처리 완료: {len(price_df)}개 레코드, 저장 경로: {output_file}\")\n",
        "            return price_df\n",
        "        except Exception as e:\n",
        "            print(f\"국내주식 가격 데이터 처리 실패: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def process_us_stock_prices(self):\n",
        "        \"\"\"\n",
        "        미국주식 일별 가격 데이터 전처리\n",
        "        - raw_data_dir의 us_price_YYYYMMDD.csv 파일 중 최신 파일 사용\n",
        "        - 주요 컬럼: Date, Open, High, Low, Close, Volume, Ticker\n",
        "        - 결측치 처리, 날짜 변환, 기술적 지표 추가, processed/us_stock_prices.pkl로 저장\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(\"미국주식 가격 데이터 처리 중...\")\n",
        "            # 최신 미국주식 가격 데이터 파일 찾기\n",
        "            price_files = sorted([f for f in os.listdir(self.raw_data_dir) if f.startswith('us_price_')], reverse=True)\n",
        "            if not price_files:\n",
        "                print(\"미국주식 가격 데이터 파일이 없습니다.\")\n",
        "                return None\n",
        "            price_file = os.path.join(self.raw_data_dir, price_files[0])\n",
        "            price_df = pd.read_csv(price_file)\n",
        "            # 날짜 변환\n",
        "            if 'Date' in price_df.columns:\n",
        "                price_df['Date'] = pd.to_datetime(price_df['Date'])\n",
        "            # 결측치 처리\n",
        "            for col in ['Open', 'High', 'Low', 'Close', 'Volume']:\n",
        "                if col in price_df.columns:\n",
        "                    price_df[col] = price_df[col].fillna(method='ffill')\n",
        "            # 기술적 지표 추가 (종목별)\n",
        "            result_dfs = []\n",
        "            for ticker, group in price_df.groupby('Ticker'):\n",
        "                group = group.sort_values('Date')\n",
        "                # 이동평균선\n",
        "                group['MA5'] = group['Close'].rolling(window=5).mean()\n",
        "                group['MA20'] = group['Close'].rolling(window=20).mean()\n",
        "                group['MA60'] = group['Close'].rolling(window=60).mean()\n",
        "                # MACD\n",
        "                ema_12 = group['Close'].ewm(span=12, adjust=False).mean()\n",
        "                ema_26 = group['Close'].ewm(span=26, adjust=False).mean()\n",
        "                group['MACD'] = ema_12 - ema_26\n",
        "                group['MACD_signal'] = group['MACD'].ewm(span=9, adjust=False).mean()\n",
        "                # RSI\n",
        "                delta = group['Close'].diff()\n",
        "                gain = delta.where(delta > 0, 0)\n",
        "                loss = -delta.where(delta < 0, 0)\n",
        "                avg_gain = gain.rolling(window=14).mean()\n",
        "                avg_loss = loss.rolling(window=14).mean()\n",
        "                rs = avg_gain / avg_loss\n",
        "                group['RSI'] = 100 - (100 / (1 + rs))\n",
        "                # 볼린저 밴드\n",
        "                group['BB_mid'] = group['Close'].rolling(window=20).mean()\n",
        "                std = group['Close'].rolling(window=20).std()\n",
        "                group['BB_upper'] = group['BB_mid'] + 2 * std\n",
        "                group['BB_lower'] = group['BB_mid'] - 2 * std\n",
        "                result_dfs.append(group)\n",
        "            if result_dfs:\n",
        "                result_df = pd.concat(result_dfs, ignore_index=True)\n",
        "            else:\n",
        "                result_df = price_df\n",
        "            # 처리된 데이터 저장\n",
        "            output_file = os.path.join(self.processed_data_dir, \"us_stock_prices.pkl\")\n",
        "            result_df.to_pickle(output_file)\n",
        "            print(f\"미국주식 가격 데이터 처리 완료: {len(result_df)}개 레코드, 저장 경로: {output_file}\")\n",
        "            return result_df\n",
        "        except Exception as e:\n",
        "            print(f\"미국주식 가격 데이터 처리 실패: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def process_us_stock_tickers(self):\n",
        "        \"\"\"\n",
        "        미국 S&P 500 티커 데이터 전처리\n",
        "        - raw_data_dir의 us_ticker_YYYYMMDD.csv 파일 중 최신 파일 사용\n",
        "        - 주요 컬럼: Ticker, Name, Market, Sector\n",
        "        - 결측치 처리, 컬럼명 정규화, processed/us_stock_tickers.pkl로 저장\n",
        "        \"\"\"\n",
        "        try:\n",
        "            print(\"미국 S&P 500 티커 데이터 처리 중...\")\n",
        "            # 최신 S&P 500 티커 파일 찾기\n",
        "            ticker_files = sorted([f for f in os.listdir(self.raw_data_dir) if f.startswith('us_ticker_')], reverse=True)\n",
        "            if not ticker_files:\n",
        "                print(\"미국 S&P 500 티커 파일이 없습니다.\")\n",
        "                return None\n",
        "            ticker_file = os.path.join(self.raw_data_dir, ticker_files[0])\n",
        "            ticker_df = pd.read_csv(ticker_file)\n",
        "            # 컬럼명 정규화\n",
        "            rename_map = {c: c.strip().capitalize() for c in ticker_df.columns}\n",
        "            ticker_df = ticker_df.rename(columns=rename_map)\n",
        "            # 결측치 처리\n",
        "            for col in ['Ticker', 'Name', 'Market', 'Sector']:\n",
        "                if col in ticker_df.columns:\n",
        "                    ticker_df[col] = ticker_df[col].fillna('')\n",
        "            # 저장\n",
        "            output_file = os.path.join(self.processed_data_dir, \"us_stock_tickers.pkl\")\n",
        "            ticker_df.to_pickle(output_file)\n",
        "            print(f\"미국 S&P 500 티커 데이터 처리 완료: {len(ticker_df)}개, 저장 경로: {output_file}\")\n",
        "            return ticker_df\n",
        "        except Exception as e:\n",
        "            print(f\"미국 S&P 500 티커 데이터 처리 실패: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def _add_technical_indicators(self, df):\n",
        "        \"\"\"주가 데이터에 기술적 지표 추가\"\"\"\n",
        "        try:\n",
        "            # 종목별로 그룹화하여 처리\n",
        "            result_dfs = []\n",
        "            \n",
        "            for ticker, group in df.groupby('종목코드'):\n",
        "                group = group.sort_values('날짜')\n",
        "                \n",
        "                # 이동평균선\n",
        "                group['MA5'] = group['종가'].rolling(window=5).mean()\n",
        "                group['MA20'] = group['종가'].rolling(window=20).mean()\n",
        "                group['MA60'] = group['종가'].rolling(window=60).mean()\n",
        "                \n",
        "                # MACD\n",
        "                ema_12 = group['종가'].ewm(span=12, adjust=False).mean()\n",
        "                ema_26 = group['종가'].ewm(span=26, adjust=False).mean()\n",
        "                group['MACD'] = ema_12 - ema_26\n",
        "                group['MACD_signal'] = group['MACD'].ewm(span=9, adjust=False).mean()\n",
        "                \n",
        "                # RSI\n",
        "                delta = group['종가'].diff()\n",
        "                gain = delta.where(delta > 0, 0)\n",
        "                loss = -delta.where(delta < 0, 0)\n",
        "                avg_gain = gain.rolling(window=14).mean()\n",
        "                avg_loss = loss.rolling(window=14).mean()\n",
        "                rs = avg_gain / avg_loss\n",
        "                group['RSI'] = 100 - (100 / (1 + rs))\n",
        "                \n",
        "                # 볼린저 밴드\n",
        "                group['BB_mid'] = group['종가'].rolling(window=20).mean()\n",
        "                std = group['종가'].rolling(window=20).std()\n",
        "                group['BB_upper'] = group['BB_mid'] + 2 * std\n",
        "                group['BB_lower'] = group['BB_mid'] - 2 * std\n",
        "                \n",
        "                # 결과 추가\n",
        "                result_dfs.append(group)\n",
        "            \n",
        "            # 모든 데이터 결합\n",
        "            if result_dfs:\n",
        "                return pd.concat(result_dfs, ignore_index=True)\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"기술적 지표 추가 실패: {e}\")\n",
        "            return df\n",
        "    \n",
        "    def process_financial_statements(self):\n",
        "        \"\"\"재무제표 데이터 처리\"\"\"\n",
        "        try:\n",
        "            print(\"재무제표 데이터 처리 중...\")\n",
        "            \n",
        "            # 최신 재무제표 데이터 파일 찾기\n",
        "            fs_files = sorted([f for f in os.listdir(self.raw_data_dir) if f.startswith('kor_fs_')], reverse=True)\n",
        "            if not fs_files:\n",
        "                print(\"재무제표 데이터 파일이 없습니다.\")\n",
        "                return None\n",
        "            \n",
        "            fs_file = os.path.join(self.raw_data_dir, fs_files[0])\n",
        "            fs_df = pd.read_csv(fs_file)\n",
        "            \n",
        "            # 데이터 전처리\n",
        "            # 종목코드 6자리로 포맷팅\n",
        "            fs_df['종목코드'] = fs_df['종목코드'].astype(str).str.zfill(6)\n",
        "            \n",
        "            # 결측치 처리\n",
        "            for col in fs_df.columns:\n",
        "                if fs_df[col].dtype in [np.float64, np.int64]:\n",
        "                    fs_df[col] = fs_df[col].fillna(0)\n",
        "            \n",
        "            # 재무비율 계산\n",
        "            fs_df = self._calculate_financial_ratios(fs_df)\n",
        "            \n",
        "            # 처리된 데이터 저장\n",
        "            output_file = os.path.join(self.processed_data_dir, \"financial_statements.pkl\")\n",
        "            fs_df.to_pickle(output_file)\n",
        "            \n",
        "            print(f\"재무제표 데이터 처리 완료: {len(fs_df)}개 레코드, 저장 경로: {output_file}\")\n",
        "            return fs_df\n",
        "        except Exception as e:\n",
        "            print(f\"재무제표 데이터 처리 실패: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def _calculate_financial_ratios(self, df):\n",
        "        \"\"\"재무제표 데이터로부터 재무비율 계산\"\"\"\n",
        "        try:\n",
        "            # 필요한 컬럼이 있는지 확인\n",
        "            required_columns = ['매출액', '영업이익', '당기순이익', '자산총계', '부채총계', '자본총계']\n",
        "            for col in required_columns:\n",
        "                if col not in df.columns:\n",
        "                    print(f\"재무비율 계산에 필요한 컬럼이 없습니다: {col}\")\n",
        "                    return df\n",
        "            \n",
        "            # 영업이익률\n",
        "            df['영업이익률'] = (df['영업이익'] / df['매출액']) * 100\n",
        "            \n",
        "            # 순이익률\n",
        "            df['순이익률'] = (df['당기순이익'] / df['매출액']) * 100\n",
        "            \n",
        "            # 부채비율\n",
        "            df['부채비율'] = (df['부채총계'] / df['자본총계']) * 100\n",
        "            \n",
        "            # 자기자본비율\n",
        "            df['자기자본비율'] = (df['자본총계'] / df['자산총계']) * 100\n",
        "            \n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"재무비율 계산 실패: {e}\")\n",
        "            return df\n",
        "    \n",
        "    def process_valuation_metrics(self):\n",
        "        \"\"\"가치평가 지표 처리\"\"\"\n",
        "        try:\n",
        "            print(\"가치평가 지표 처리 중...\")\n",
        "            \n",
        "            # 최신 가치평가 지표 파일 찾기\n",
        "            value_files = sorted([f for f in os.listdir(self.raw_data_dir) if f.startswith('kor_value_')], reverse=True)\n",
        "            if not value_files:\n",
        "                print(\"가치평가 지표 파일이 없습니다.\")\n",
        "                return None\n",
        "            \n",
        "            value_file = os.path.join(self.raw_data_dir, value_files[0])\n",
        "            value_df = pd.read_csv(value_file)\n",
        "            \n",
        "            # 데이터 전처리\n",
        "            # 종목코드 6자리로 포맷팅\n",
        "            value_df['종목코드'] = value_df['종목코드'].astype(str).str.zfill(6)\n",
        "            \n",
        "            # 결측치 처리\n",
        "            for col in value_df.columns:\n",
        "                if value_df[col].dtype in [np.float64, np.int64]:\n",
        "                    value_df[col] = value_df[col].fillna(value_df[col].median())\n",
        "            \n",
        "            # 처리된 데이터 저장\n",
        "            output_file = os.path.join(self.processed_data_dir, \"valuation_metrics.pkl\")\n",
        "            value_df.to_pickle(output_file)\n",
        "            \n",
        "            print(f\"가치평가 지표 처리 완료: {len(value_df)}개 레코드, 저장 경로: {output_file}\")\n",
        "            return value_df\n",
        "        except Exception as e:\n",
        "            print(f\"가치평가 지표 처리 실패: {e}\")\n",
        "            return None\n",
        "    \n",
        "    def build_vector_db(self):\n",
        "        \"\"\"벡터 DB 구축\"\"\"\n",
        "        try:\n",
        "            print(\"벡터 DB 구축 중...\")\n",
        "            \n",
        "            if not self.embedding_model:\n",
        "                print(\"임베딩 모델이 로드되지 않았습니다.\")\n",
        "                return False\n",
        "            \n",
        "            # 종목 정보 로드\n",
        "            ticker_files = sorted([f for f in os.listdir(self.raw_data_dir) if f.startswith('kor_ticker_')], reverse=True)\n",
        "            if not ticker_files:\n",
        "                print(\"종목 코드 파일이 없습니다.\")\n",
        "                return False\n",
        "            \n",
        "            ticker_file = os.path.join(self.raw_data_dir, ticker_files[0])\n",
        "            ticker_df = pd.read_csv(ticker_file)\n",
        "            \n",
        "            # 섹터 정보 로드\n",
        "            sector_files = sorted([f for f in os.listdir(self.raw_data_dir) if f.startswith('kor_sector_')], reverse=True)\n",
        "            if sector_files:\n",
        "                sector_file = os.path.join(self.raw_data_dir, sector_files[0])\n",
        "                sector_df = pd.read_csv(sector_file)\n",
        "            else:\n",
        "                sector_df = None\n",
        "            \n",
        "            # 가치평가 지표 로드\n",
        "            value_files = sorted([f for f in os.listdir(self.raw_data_dir) if f.startswith('kor_value_')], reverse=True)\n",
        "            if value_files:\n",
        "                value_file = os.path.join(self.raw_data_dir, value_files[0])\n",
        "                value_df = pd.read_csv(value_file)\n",
        "            else:\n",
        "                value_df = None\n",
        "            \n",
        "            # 문서 생성\n",
        "            documents = []\n",
        "            \n",
        "            # 종목 정보 문서\n",
        "            for _, row in ticker_df.iterrows():\n",
        "                ticker = row['종목코드']\n",
        "                name = row['종목명']\n",
        "                market = row.get('시장구분', '')\n",
        "                \n",
        "                # 섹터 정보 추가\n",
        "                sector = ''\n",
        "                if sector_df is not None:\n",
        "                    sector_row = sector_df[sector_df['종목코드'] == ticker]\n",
        "                    if not sector_row.empty:\n",
        "                        sector = sector_row.iloc[0].get('sector', '')\n",
        "                \n",
        "                # 가치평가 지표 추가\n",
        "                per, pbr = '', ''\n",
        "                if value_df is not None:\n",
        "                    value_row = value_df[value_df['종목코드'] == ticker]\n",
        "                    if not value_row.empty:\n",
        "                        per = value_row.iloc[0].get('PER', '')\n",
        "                        pbr = value_row.iloc[0].get('PBR', '')\n",
        "                \n",
        "                # 문서 생성\n",
        "                doc = f\"{name}({ticker})는 {market} 시장에 상장된 {sector} 섹터 기업입니다.\"\n",
        "                if per and pbr:\n",
        "                    doc += f\" PER은 {per}, PBR은 {pbr}입니다.\"\n",
        "                \n",
        "                documents.append({\n",
        "                    'content': doc,\n",
        "                    'metadata': {\n",
        "                        'ticker': ticker,\n",
        "                        'name': name,\n",
        "                        'market': market,\n",
        "                        'sector': sector\n",
        "                    }\n",
        "                })\n",
        "            \n",
        "            # 문서 임베딩 생성\n",
        "            embeddings = []\n",
        "            for doc in documents:\n",
        "                embedding = self.embedding_model.encode(doc['content'])\n",
        "                embeddings.append(embedding)\n",
        "            \n",
        "            # FAISS 인덱스 생성\n",
        "            embeddings_np = np.array(embeddings).astype('float32')\n",
        "            dimension = embeddings_np.shape[1]\n",
        "            self.vector_db_index = faiss.IndexFlatL2(dimension)\n",
        "            self.vector_db_index.add(embeddings_np)\n",
        "            \n",
        "            # 문서 저장\n",
        "            self.document_store = documents\n",
        "            \n",
        "            # 벡터 DB 저장\n",
        "            index_file = os.path.join(self.processed_data_dir, \"vector_db_index.bin\")\n",
        "            faiss.write_index(self.vector_db_index, index_file)\n",
        "            \n",
        "            # 문서 저장\n",
        "            docs_file = os.path.join(self.processed_data_dir, \"vector_db_documents.json\")\n",
        "            with open(docs_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(self.document_store, f, ensure_ascii=False, indent=2)\n",
        "            \n",
        "            print(f\"벡터 DB 구축 완료: {len(documents)}개 문서, 저장 경로: {index_file}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"벡터 DB 구축 실패: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def search_vector_db(self, query, top_k=5):\n",
        "        \"\"\"벡터 DB 검색\"\"\"\n",
        "        try:\n",
        "            if not self.embedding_model or self.vector_db_index is None:\n",
        "                # 벡터 DB 로드 시도\n",
        "                index_file = os.path.join(self.processed_data_dir, \"vector_db_index.bin\")\n",
        "                docs_file = os.path.join(self.processed_data_dir, \"vector_db_documents.json\")\n",
        "                \n",
        "                if os.path.exists(index_file) and os.path.exists(docs_file):\n",
        "                    self.vector_db_index = faiss.read_index(index_file)\n",
        "                    with open(docs_file, 'r', encoding='utf-8') as f:\n",
        "                        self.document_store = json.load(f)\n",
        "                else:\n",
        "                    print(\"벡터 DB가 구축되지 않았습니다.\")\n",
        "                    return []\n",
        "            \n",
        "            # 쿼리 임베딩 생성\n",
        "            query_embedding = self.embedding_model.encode(query)\n",
        "            query_embedding_np = np.array([query_embedding]).astype('float32')\n",
        "            \n",
        "            # 검색\n",
        "            distances, indices = self.vector_db_index.search(query_embedding_np, top_k)\n",
        "            \n",
        "            # 결과 반환\n",
        "            results = []\n",
        "            for i, idx in enumerate(indices[0]):\n",
        "                if idx < len(self.document_store):\n",
        "                    doc = self.document_store[idx]\n",
        "                    results.append({\n",
        "                        'content': doc['content'],\n",
        "                        'metadata': doc['metadata'],\n",
        "                        'distance': float(distances[0][i])\n",
        "                    })\n",
        "            \n",
        "            return results\n",
        "        except Exception as e:\n",
        "            print(f\"벡터 DB 검색 실패: {e}\")\n",
        "            return []\n",
        "    \n",
        "    def run_all_processors(self):\n",
        "        \"\"\"모든 데이터 처리 함수 실행\"\"\"\n",
        "        print(\"모든 데이터 처리 시작...\")\n",
        "        \n",
        "        # 종목 코드 데이터 처리\n",
        "        self.process_stock_tickers()\n",
        "        \n",
        "        # 주식 가격 데이터 처리\n",
        "        self.process_stock_prices()\n",
        "        \n",
        "        # 재무제표 데이터 처리\n",
        "        self.process_financial_statements()\n",
        "        \n",
        "        # 가치평가 지표 처리\n",
        "        self.process_valuation_metrics()\n",
        "        \n",
        "        # 벡터 DB 구축\n",
        "        self.build_vector_db()\n",
        "        \n",
        "        print(\"모든 데이터 처리 완료\")\n",
        "\n",
        "# 모듈 테스트용 코드\n",
        "if __name__ == \"__main__\":\n",
        "    processor = DataProcessor()\n",
        "    processor.run_all_processors() "
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
